{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxYEI4q6s3Fm"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd # For csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import requests\n",
        "import pickle\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protein Disorder Prediction"
      ],
      "metadata": {
        "id": "SrYf5mUlnjb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data set-up"
      ],
      "metadata": {
        "id": "ebjZeL7Wu-rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import drive, so that preprocessed data can be used in Notebook."
      ],
      "metadata": {
        "id": "8FElE8EiQhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2WcDvDHutzeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1171d182-f655-4f06-fece-7e65124786c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick access to preprocessed data, instead of downloading it each time Notebook is opened."
      ],
      "metadata": {
        "id": "Es5pCp8KeX4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_sequences():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/sequence_data.json', 'r') as infile:\n",
        "    return json.load(infile)\n",
        "\n",
        "def read_cleaned_pandas_data():\n",
        "  return pd.read_json('/content/drive/My Drive/Colab Notebooks/diss_files/idr_pandas_table.json')\n",
        "\n",
        "protein_sequences_n_ids = read_sequences()\n",
        "fully_clean_pandas_data = read_cleaned_pandas_data()"
      ],
      "metadata": {
        "id": "r9k7T6sTaLMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amino Acids Channeled Image"
      ],
      "metadata": {
        "id": "gipyUHo2a14x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_empty_image(seq):\n",
        "  img = {\n",
        "    'A' : np.zeros(len(seq)),\n",
        "    'C' : np.zeros(len(seq)),\n",
        "    'D' : np.zeros(len(seq)),\n",
        "    'E' : np.zeros(len(seq)),\n",
        "    'F' : np.zeros(len(seq)),\n",
        "    'G' : np.zeros(len(seq)),\n",
        "    'H' : np.zeros(len(seq)),\n",
        "    'I' : np.zeros(len(seq)),\n",
        "    'K' : np.zeros(len(seq)),\n",
        "    'L' : np.zeros(len(seq)),\n",
        "    'M' : np.zeros(len(seq)),\n",
        "    'N' : np.zeros(len(seq)),\n",
        "    'P' : np.zeros(len(seq)),\n",
        "    'Q' : np.zeros(len(seq)),\n",
        "    'R' : np.zeros(len(seq)),\n",
        "    'S' : np.zeros(len(seq)),\n",
        "    'T' : np.zeros(len(seq)),\n",
        "    'V' : np.zeros(len(seq)),\n",
        "    'W' : np.zeros(len(seq)),\n",
        "    'Y' : np.zeros(len(seq))\n",
        "  }\n",
        "  return img\n",
        "\n",
        "def make_image(seq):\n",
        "  # Makes 20 empty channels\n",
        "  channeled_img = make_empty_image(seq)\n",
        "  # Loop over each amino acid in the sequence - \n",
        "  # for its position add a 1 to the letter identifier channel\n",
        "  for i, char in enumerate(seq):\n",
        "    # Updates array due to arrays being like pointers\n",
        "    channeled_img.get(char)[i] = 1\n",
        "\n",
        "  return channeled_img"
      ],
      "metadata": {
        "id": "vWSLWOaK-2A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset class for our data. "
      ],
      "metadata": {
        "id": "79WpGfwSqHFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisProtDataset(Dataset):\n",
        "    def __init__(self, pandas_table, amino_map, protein_sequences, transform=None):\n",
        "        self.disorder_prot = pandas_table\n",
        "        self.sequence_map = make_image\n",
        "        self.sequences = protein_sequences\n",
        "        self.tranform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.disorder_prot)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Protein accession number - key identifier\n",
        "        acc = self.disorder_prot['acc'].loc[idx]\n",
        "        idrs = self.disorder_prot['disordered_regions'].loc[idx]\n",
        "        \n",
        "        # Get sequence\n",
        "        protein_sequence = self.sequences.get(acc)\n",
        "        # Vectorise amino acids\n",
        "        protein_sequence_image = self.sequence_map(protein_sequence)\n",
        "        # Converts channel dictionary to 2D array\n",
        "        protein_sequence_image = np.array(list(protein_sequence_image.values()))\n",
        "        \n",
        "        # Create order/disorder label\n",
        "        disorder_label = np.zeros(len(protein_sequence))\n",
        "        for (start, end) in idrs:\n",
        "          disorder_label[start-1:end] = 1\n",
        "\n",
        "        get_dict = {'acc': acc, 'image': protein_sequence_image, 'label': disorder_label}\n",
        "        return get_dict"
      ],
      "metadata": {
        "id": "2hbU6qcbknvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate train/validation/test datasets. Currently using a 60/20/20 in place split from generated pandas data."
      ],
      "metadata": {
        "id": "LVya_gCvf8Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "randomly_sampled_pandas_data = fully_clean_pandas_data.sample(frac = 1, random_state=117).reset_index()\n",
        "\n",
        "train_len = round(len(randomly_sampled_pandas_data) * (60/100))\n",
        "train_pandas_data = randomly_sampled_pandas_data[0:train_len]\n",
        "train_dataset = DisProtDataset(train_pandas_data, make_image, protein_sequences_n_ids)\n",
        "\n",
        "valid_len = round((len(randomly_sampled_pandas_data) * (20/100)))\n",
        "valid_pandas_data = randomly_sampled_pandas_data[train_len:(train_len+valid_len)]\n",
        "# Reset index helps clean up index column after slicing.\n",
        "valid_pandas_data = valid_pandas_data.reset_index(drop=True)\n",
        "validation_dataset = DisProtDataset(valid_pandas_data, make_image, protein_sequences_n_ids)\n",
        "\n",
        "test_len = len(randomly_sampled_pandas_data) - (train_len + valid_len)\n",
        "test_pandas_data = randomly_sampled_pandas_data[(train_len+valid_len):]\n",
        "test_pandas_data = test_pandas_data.reset_index(drop=True)\n",
        "test_dataset = DisProtDataset(test_pandas_data, make_image, protein_sequences_n_ids)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "idlEpTV1eASB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch NN. FCN model"
      ],
      "metadata": {
        "id": "sXw_YBXOohYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(20, 10, 21, padding=10)\n",
        "        self.conv2 = nn.Conv1d(10, 10, 21, padding=10)\n",
        "        self.conv3 = nn.Conv1d(10, 10, 21, padding=10)\n",
        "        self.conv4 = nn.Conv1d(10, 10, 21, padding=10)\n",
        "        self.conv5 = nn.Conv1d(10, 1, 21, padding=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.conv5(x)\n",
        "        # Removal of final activation function due to Logits Loss\n",
        "        #x = torch.sigmoid(self.conv5(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "xMpITwNXTbQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model"
      ],
      "metadata": {
        "id": "zEPD-11xTDsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reads trained model from storage\n",
        "def read_model():\n",
        "  PATH = '/content/drive/My Drive/Colab Notebooks/diss_files/cnn_net.pth'\n",
        "\n",
        "  loaded_model = FCN_Net()\n",
        "  loaded_model.load_state_dict(torch.load(PATH))\n",
        "  return loaded_model"
      ],
      "metadata": {
        "id": "e84RuBaW6oq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = read_model()\n",
        "loaded_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnJvpbSBLROA",
        "outputId": "3f8efe6a-3a59-4c14-b306-c4a940b741b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FCN_Net(\n",
              "  (conv1): Conv1d(20, 10, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              "  (conv2): Conv1d(10, 10, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              "  (conv3): Conv1d(10, 10, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              "  (conv4): Conv1d(10, 10, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              "  (conv5): Conv1d(10, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing a single protein sequence. This will be useful to understand the models behaviour when given a single sequence to predict."
      ],
      "metadata": {
        "id": "IwZ_vDUTWuoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turns the prediction to a list of ordered/disordered (0/1) predictions\n",
        "def pred_round(predicted_label):\n",
        "  predicted_label[predicted_label>=0.5] = 1\n",
        "  predicted_label[predicted_label<0.5] = 0\n",
        "  return predicted_label\n",
        "\n",
        "\n",
        "def make_single_seq_to_test_loaded_model(loaded_model):\n",
        "  \n",
        "  acc, vectorised_image, true_label = train_dataset[0].values()\n",
        "  vectorised_image = torch.tensor(vectorised_image)\n",
        "  vectorised_image = vectorised_image.type(torch.FloatTensor)\n",
        "  true_label = torch.tensor(true_label)\n",
        "  true_label = true_label.type(torch.FloatTensor)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    predicted_label = loaded_model(vectorised_image)\n",
        "\n",
        "  predicted_label = torch.sigmoid(predicted_label)\n",
        "  predicted_label = torch.squeeze(predicted_label)\n",
        "  pred_lab = pred_round(predicted_label)\n",
        "  print(pred_lab)\n",
        "\n",
        "make_single_seq_to_test_loaded_model(loaded_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4qVjm6JKCaz",
        "outputId": "b3437d93-780e-4b20-ff13-98f3790bbd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file below can be used with an external Python file, then with the Django webapp to ensure the planned process works."
      ],
      "metadata": {
        "id": "AuAsRddTXMwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_sequence():\n",
        "  acc, vectorised_image, true_label = train_dataset[0].values()\n",
        "  reusable_test_seq = {'vector_seq' : vectorised_image, 'true_label' : true_label}\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/single_sequence.txt', 'wb') as outfile:\n",
        "    pickle.dump(reusable_test_seq, outfile)\n",
        "\n",
        "write_sequence()"
      ],
      "metadata": {
        "id": "y-ZHymyadXmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_sequence():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/single_sequence.txt', 'rb') as infile:\n",
        "    return pickle.load(infile)\n",
        "\n",
        "single_test_seq_loaded = read_sequence()"
      ],
      "metadata": {
        "id": "k9y9BFzFdhgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq, lab = single_test_seq_loaded.values()\n",
        "seq = torch.tensor(seq)\n",
        "seq = seq.type(torch.FloatTensor)\n",
        "lab = torch.tensor(lab)\n",
        "lab = lab.type(torch.FloatTensor)\n",
        "\n",
        "with torch.no_grad():\n",
        "    predicted_label = loaded_model(seq)\n",
        "\n",
        "predicted_label = torch.sigmoid(predicted_label)\n",
        "predicted_label = torch.squeeze(predicted_label)\n",
        "pred_lab = pred_round(predicted_label)\n",
        "pred_lab, lab"
      ],
      "metadata": {
        "id": "umnu3yHYXj8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22a10af-5da8-4665-dcc9-1d9e437ff747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rn51pTClNbAG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}