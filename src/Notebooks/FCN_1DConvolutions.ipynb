{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vxYEI4q6s3Fm"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd # For csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import requests\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protein Disorder Prediction"
      ],
      "metadata": {
        "id": "SrYf5mUlnjb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data set-up"
      ],
      "metadata": {
        "id": "ebjZeL7Wu-rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import drive, so that DisProt.tsv can be read (assuming downloaded). Future adaption to use API to request TSV."
      ],
      "metadata": {
        "id": "8FElE8EiQhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2WcDvDHutzeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185b42de-acaf-4cbb-e53b-8ab2155d3f3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amino Acids Channeled Image"
      ],
      "metadata": {
        "id": "gipyUHo2a14x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_empty_image(seq):\n",
        "  img = {\n",
        "    'A' : np.zeros(len(seq)),\n",
        "    'C' : np.zeros(len(seq)),\n",
        "    'D' : np.zeros(len(seq)),\n",
        "    'E' : np.zeros(len(seq)),\n",
        "    'F' : np.zeros(len(seq)),\n",
        "    'G' : np.zeros(len(seq)),\n",
        "    'H' : np.zeros(len(seq)),\n",
        "    'I' : np.zeros(len(seq)),\n",
        "    'K' : np.zeros(len(seq)),\n",
        "    'L' : np.zeros(len(seq)),\n",
        "    'M' : np.zeros(len(seq)),\n",
        "    'N' : np.zeros(len(seq)),\n",
        "    'P' : np.zeros(len(seq)),\n",
        "    'Q' : np.zeros(len(seq)),\n",
        "    'R' : np.zeros(len(seq)),\n",
        "    'S' : np.zeros(len(seq)),\n",
        "    'T' : np.zeros(len(seq)),\n",
        "    'V' : np.zeros(len(seq)),\n",
        "    'W' : np.zeros(len(seq)),\n",
        "    'Y' : np.zeros(len(seq))\n",
        "  }\n",
        "  return img\n",
        "\n",
        "def make_image(seq):\n",
        "  # Makes 20 empty channels\n",
        "  channeled_img = make_empty_image(seq)\n",
        "  # Loop over each amino acid in the sequence - \n",
        "  # for its position add a 1 to the letter identifier channel\n",
        "  for i, char in enumerate(seq):\n",
        "    # Updates array due to arrays being like pointers\n",
        "    channeled_img.get(char)[i] = 1\n",
        "\n",
        "  return channeled_img"
      ],
      "metadata": {
        "id": "vWSLWOaK-2A9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from DisProt TSV - https://disprot.org/download\n",
        "data_disprot = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DL-DISS/DisProt_v1.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "Zc5IeaTI5Vtw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary for important data from DisProt\n",
        "disorder_start_and_end = {}\n",
        "\n",
        "for i, acc in enumerate(data_disprot['acc']):\n",
        "  s = data_disprot['start'][i]\n",
        "  e = data_disprot['end'][i]\n",
        "  arr = disorder_start_and_end.get((str(acc)), [])\n",
        "\n",
        "  if (s, e) not in arr:\n",
        "    disorder_start_and_end[str(acc)] = arr + [(s, e)]\n"
      ],
      "metadata": {
        "id": "xG6dyQnBKQLg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new table for important DisProt data\n",
        "data = {'acc': disorder_start_and_end.keys(), 'disordered_regions': disorder_start_and_end.values()}"
      ],
      "metadata": {
        "id": "moNeeyrlMpc8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(data)"
      ],
      "metadata": {
        "id": "CZ7zmVQONJao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "920b77ae-3cc1-4b5c-fa5a-1572776234a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             acc                                disordered_regions\n",
              "0         P03265                          [(294, 334), (454, 464)]\n",
              "1         P49913                                      [(134, 170)]\n",
              "2         P03045            [(1, 107), (1, 22), (34, 47), (1, 36)]\n",
              "3         P00004                              [(1, 104), (2, 105)]\n",
              "4         P27695             [(1, 42), (1, 36), (32, 43), (2, 40)]\n",
              "...          ...                                               ...\n",
              "2414  A0A5P2U9X4  [(350, 525), (460, 521), (417, 426), (450, 525)]\n",
              "2415      P40939                                      [(637, 647)]\n",
              "2416      Q6CSX2                                      [(562, 831)]\n",
              "2417      Q8IYT8                                      [(168, 177)]\n",
              "2418      Q9UHK0                                      [(486, 495)]\n",
              "\n",
              "[2419 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf78ba94-ad6e-473f-9284-ef103eea24aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>disordered_regions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P03265</td>\n",
              "      <td>[(294, 334), (454, 464)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P49913</td>\n",
              "      <td>[(134, 170)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P03045</td>\n",
              "      <td>[(1, 107), (1, 22), (34, 47), (1, 36)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P00004</td>\n",
              "      <td>[(1, 104), (2, 105)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P27695</td>\n",
              "      <td>[(1, 42), (1, 36), (32, 43), (2, 40)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>A0A5P2U9X4</td>\n",
              "      <td>[(350, 525), (460, 521), (417, 426), (450, 525)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>P40939</td>\n",
              "      <td>[(637, 647)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>Q6CSX2</td>\n",
              "      <td>[(562, 831)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2417</th>\n",
              "      <td>Q8IYT8</td>\n",
              "      <td>[(168, 177)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2418</th>\n",
              "      <td>Q9UHK0</td>\n",
              "      <td>[(486, 495)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2419 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf78ba94-ad6e-473f-9284-ef103eea24aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf78ba94-ad6e-473f-9284-ef103eea24aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf78ba94-ad6e-473f-9284-ef103eea24aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_data = pd.DataFrame.from_dict(data)"
      ],
      "metadata": {
        "id": "2zdirGSM1mLG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proteins in this dataframe are preprocessed to get their full sequences from UniProt."
      ],
      "metadata": {
        "id": "UgikDmCOs6pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing - download all sequences.\n",
        "def preprocess_sequences(pandas_data):\n",
        "  protSeqDict = {}\n",
        "  for row in range(len(pandas_data)):\n",
        "    acc = pandas_data['acc'].loc[row]\n",
        "\n",
        "    url = f'https://www.uniprot.org/uniprotkb/{str(acc)}.fasta'\n",
        "    uniprot_fasta = requests.get(url).text\n",
        "    # Gets the sequence as a string of amino acids\n",
        "    protein_sequence = uniprot_fasta.split('\\n')[1:]\n",
        "    protein_sequence = ''.join(protein_sequence)\n",
        "\n",
        "    if protein_sequence == '':\n",
        "      continue\n",
        "\n",
        "    protSeqDict[acc] = protein_sequence\n",
        "  return protSeqDict\n",
        "\n",
        "protein_sequences_n_ids = preprocess_sequences(pandas_data)"
      ],
      "metadata": {
        "id": "__HLboQMkuC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/DL-DISS/uniSeqData.txt', 'wb') as outfile:\n",
        "    pickle.dump(protein_sequences_n_ids, outfile)"
      ],
      "metadata": {
        "id": "zeWa776Z6oCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick access to preprocessed data, instead of downloading it each time Notebook is opened."
      ],
      "metadata": {
        "id": "Es5pCp8KeX4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/DL-DISS/uniSeqData.txt', 'rb') as infile:\n",
        "    protein_sequences_n_ids = pickle.load(infile)"
      ],
      "metadata": {
        "id": "BfOrcmCH7mpr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing protein data that is incompatible with my solution."
      ],
      "metadata": {
        "id": "rLif_xOQeo_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_pandas_data = pandas_data\n",
        "x = protein_sequences_n_ids.keys()\n",
        "for acc in pandas_data['acc']:\n",
        "  if acc in x:\n",
        "    continue\n",
        "  else:\n",
        "    index_to_drop = clean_pandas_data[clean_pandas_data['acc'] == acc].index.tolist()[0]\n",
        "    clean_pandas_data = clean_pandas_data.drop(index_to_drop)"
      ],
      "metadata": {
        "id": "hBSpgSf24pev"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in clean_pandas_data['acc']:\n",
        "  seqq = protein_sequences_n_ids.get(acc)\n",
        "  if 'X' in seqq or 'U' in seqq or 'Z' in seqq:\n",
        "    index_to_drop = clean_pandas_data[clean_pandas_data['acc'] == acc].index.tolist()[0]\n",
        "    clean_pandas_data = clean_pandas_data.drop(index_to_drop)\n",
        "\n",
        "print(len(clean_pandas_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSnFFs37mo3",
        "outputId": "f755eadc-92f3-4283-f836-214bdbbe6793"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = {'acc': (clean_pandas_data['acc'].tolist()), 'disordered_regions': (clean_pandas_data['disordered_regions'].tolist())}\n",
        "fully_clean_pandas_data = pd.DataFrame.from_dict(clean_data)"
      ],
      "metadata": {
        "id": "ztRDb1LuMWHQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset class for our data. \n",
        "- Takes in pandas data (usually full TSV).\n",
        "- The amino acid vectorising map.\n",
        "- A dictionary mapping protein accession numbers to their sequence (generated from preprocessing)."
      ],
      "metadata": {
        "id": "79WpGfwSqHFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisProtDataset(Dataset):\n",
        "    def __init__(self, pandas_table, amino_map, protein_sequences, transform=None):\n",
        "        self.disorder_prot = pandas_table\n",
        "        self.sequence_map = make_image\n",
        "        self.sequences = protein_sequences\n",
        "        self.tranform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.disorder_prot)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Protein accession number - key identifier\n",
        "        acc = self.disorder_prot['acc'].loc[idx]\n",
        "        idrs = self.disorder_prot['disordered_regions'].loc[idx]\n",
        "        \n",
        "        # Get sequence\n",
        "        protein_sequence = self.sequences.get(acc)\n",
        "        # Vectorise amino acids\n",
        "        protein_sequence_image = self.sequence_map(protein_sequence)\n",
        "        # Converts channel dictionary to 2D array\n",
        "        protein_sequence_image = np.array(list(protein_sequence_image.values()))\n",
        "        \n",
        "        # Create order/disorder label\n",
        "        disorder_label = np.zeros(len(protein_sequence))\n",
        "        for (start, end) in idrs:\n",
        "          disorder_label[start-1:end] = 1\n",
        "\n",
        "        get_dict = {'acc': acc, 'image': protein_sequence_image, 'label': disorder_label}\n",
        "        return get_dict"
      ],
      "metadata": {
        "id": "2hbU6qcbknvs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiates instance variable of DisProtDataset class\n",
        "formed_dataset_class = DisProtDataset(fully_clean_pandas_data, make_image, protein_sequences_n_ids)"
      ],
      "metadata": {
        "id": "jwhnoilg1RaT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can test output of class\n",
        "formed_dataset_class[0]"
      ],
      "metadata": {
        "id": "Nz-nheMD1Xsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f738c5e4-2f30-4100-a8ff-6319872b200e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 'P03265', 'image': array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]), 'label': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(formed_dataset_class[0].get('image')).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7IbYflr_EXu",
        "outputId": "bc9ef59e-123d-4835-a43d-816a87ac9520"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 529)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dataloader using the instance variable."
      ],
      "metadata": {
        "id": "tlP1hljAq-za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(formed_dataset_class, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "# Check data loaded\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch)\n",
        "    print(sample_batched)\n",
        "    # observe 4th batch and stop.\n",
        "    if i_batch == 3:\n",
        "        break"
      ],
      "metadata": {
        "id": "8BFbZ3We8Dk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bab23ef-7c8f-41e1-e27e-4bc804b2aed1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "{'acc': ['P40517'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]], dtype=torch.float64)}\n",
            "1\n",
            "{'acc': ['Q62420'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)}\n",
            "2\n",
            "{'acc': ['P38516'], 'image': tensor([[[0., 1., 0.,  ..., 0., 0., 1.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0.]], dtype=torch.float64)}\n",
            "3\n",
            "{'acc': ['P24864'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 1.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "       dtype=torch.float64)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creates a data iterator.\n",
        "- This is similar to the dataloader.\n",
        "- After the item has been used it is removed from the 'iterator'.\n",
        "- Can randomly shuffle items about. But removes them after used, so doesn't accidentally repeat sequences."
      ],
      "metadata": {
        "id": "Im_Pi-b9tcpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing how to get samples from dataloader using dataiter\n",
        "dataiter = iter(dataloader)\n",
        "for i, sam in enumerate(dataiter):\n",
        "  print(sam)\n",
        "  if i == 2:\n",
        "    break\n",
        "\n",
        "acc, image, label = next(dataiter).values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHoNNB8GG8Rq",
        "outputId": "785f90e0-06d3-4386-8d95-a1320b7729e9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'acc': ['A0A3S5Y0Q5'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)}\n",
            "{'acc': ['P00127'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]], dtype=torch.float64)}\n",
            "{'acc': ['P63241'], 'image': tensor([[[0., 1., 0.,  ..., 0., 1., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with a PyTorch NN. FCN model"
      ],
      "metadata": {
        "id": "sXw_YBXOohYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses 1D Convolution kernels\n",
        "\n",
        "model = nn.Sequential(collections.OrderedDict([\n",
        "          ('conv1', nn.Conv1d(20, 10, 21, padding=10)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('conv2', nn.Conv1d(10, 10, 21, padding=10)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('conv3', nn.Conv1d(10, 1, 21, padding=10)),\n",
        "          ('sig1', nn.Sigmoid())\n",
        "        ]))"
      ],
      "metadata": {
        "id": "fUYOZvHI460D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the dataiter - to ensure all rows are in the iterator when iterator is looped through\n",
        "dataiter = iter(dataloader)"
      ],
      "metadata": {
        "id": "5033yX8C1Fq7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model, given DisProt dataset"
      ],
      "metadata": {
        "id": "NAQwoAkAwOQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "epoch_print_gap = 1\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    #model = model.to(device)\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        \n",
        "        running_loss_train = 0.0\n",
        "\n",
        "        # Where i is a counter and sam is a dictionary\n",
        "        for i, sam in enumerate(train_loader):\n",
        "          acc, image, label = sam.values() #sam['acc'], sam['image'], sam['label']\n",
        "          NN_input = image.type(torch.FloatTensor)\n",
        "          expected_output = label.type(torch.FloatTensor)\n",
        "\n",
        "          output = model(NN_input)\n",
        "          squeezed_o = torch.squeeze(output)\n",
        "          squeezed_e_o = torch.squeeze(expected_output)\n",
        "\n",
        "          loss = loss_fn(squeezed_o, squeezed_e_o)          \n",
        "          loss.backward()\n",
        "          running_loss_train += loss.item()\n",
        "\n",
        "          # This has effect of batches of size 16.\n",
        "          if (i+1) % 16 == 0:        \n",
        "            optimizer.step()\n",
        "            # Zero the parameter gradients\n",
        "            # Note - this zeros anything accumulated by loss.backward()\n",
        "            optimizer.zero_grad()\n",
        "          \n",
        "          # Print loss throughout epoch\n",
        "          if (i+1) % 500 == 0:\n",
        "            print(\"Epoch: \"+str(epoch), end=\" \")\n",
        "            print(\"Current loss: \"+str(running_loss_train / 500))\n",
        "            running_loss_train = 0.0\n",
        "\n",
        "        if epoch == 1 or epoch % epoch_print_gap == 0:\n",
        "            print(\"Epoch\", epoch, \"Done \\n\\n\")\n",
        "\n",
        "\n",
        "# Main\n",
        "lamb=0.001    # L2 weight decay term\n",
        "lr = 0.001\n",
        "epochs = 3\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=lamb) # This is adding L2 regularisation with factor lamb to every parameter\n",
        "training_loop(epochs, optimizer, model, criterion, dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8K1W3SHYx7x",
        "outputId": "74fc13a5-2437-49a2-c6ec-cd5382d8b6f8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Current loss: 0.6383503780364991\n",
            "Epoch: 1 Current loss: 0.5868662053346634\n",
            "Epoch: 1 Current loss: 0.5633245394527913\n",
            "Epoch: 1 Current loss: 0.5637900549471379\n",
            "Epoch 1 Done \n",
            "\n",
            "\n",
            "Epoch: 2 Current loss: 0.531167193904519\n",
            "Epoch: 2 Current loss: 0.516006025493145\n",
            "Epoch: 2 Current loss: 0.5040229924917221\n",
            "Epoch: 2 Current loss: 0.5189556149691343\n",
            "Epoch 2 Done \n",
            "\n",
            "\n",
            "Epoch: 3 Current loss: 0.5107801219820977\n",
            "Epoch: 3 Current loss: 0.5010962297767401\n",
            "Epoch: 3 Current loss: 0.5087641105353832\n",
            "Epoch: 3 Current loss: 0.510286563128233\n",
            "Epoch 3 Done \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJWE6Ul0Yy9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}