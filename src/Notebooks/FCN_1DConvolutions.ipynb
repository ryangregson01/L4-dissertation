{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vxYEI4q6s3Fm"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd # For csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import requests\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protein Disorder Prediction"
      ],
      "metadata": {
        "id": "SrYf5mUlnjb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data set-up"
      ],
      "metadata": {
        "id": "ebjZeL7Wu-rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import drive, so that DisProt.tsv can be read (assuming downloaded). Future adaption to use API to request TSV."
      ],
      "metadata": {
        "id": "8FElE8EiQhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2WcDvDHutzeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cb44a9-3b5e-42db-fe25-3e3b16a36af6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amino Acids Channeled Image"
      ],
      "metadata": {
        "id": "gipyUHo2a14x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_empty_image(seq):\n",
        "  img = {\n",
        "    'A' : np.zeros(len(seq)),\n",
        "    'C' : np.zeros(len(seq)),\n",
        "    'D' : np.zeros(len(seq)),\n",
        "    'E' : np.zeros(len(seq)),\n",
        "    'F' : np.zeros(len(seq)),\n",
        "    'G' : np.zeros(len(seq)),\n",
        "    'H' : np.zeros(len(seq)),\n",
        "    'I' : np.zeros(len(seq)),\n",
        "    'K' : np.zeros(len(seq)),\n",
        "    'L' : np.zeros(len(seq)),\n",
        "    'M' : np.zeros(len(seq)),\n",
        "    'N' : np.zeros(len(seq)),\n",
        "    'P' : np.zeros(len(seq)),\n",
        "    'Q' : np.zeros(len(seq)),\n",
        "    'R' : np.zeros(len(seq)),\n",
        "    'S' : np.zeros(len(seq)),\n",
        "    'T' : np.zeros(len(seq)),\n",
        "    'V' : np.zeros(len(seq)),\n",
        "    'W' : np.zeros(len(seq)),\n",
        "    'Y' : np.zeros(len(seq))\n",
        "  }\n",
        "  return img\n",
        "\n",
        "def make_image(seq):\n",
        "  # Makes 20 empty channels\n",
        "  channeled_img = make_empty_image(seq)\n",
        "  # Loop over each amino acid in the sequence - \n",
        "  # for its position add a 1 to the letter identifier channel\n",
        "  for i, char in enumerate(seq):\n",
        "    # Updates array due to arrays being like pointers\n",
        "    channeled_img.get(char)[i] = 1\n",
        "\n",
        "  return channeled_img"
      ],
      "metadata": {
        "id": "vWSLWOaK-2A9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from DisProt TSV - https://disprot.org/download\n",
        "data_disprot = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DL-DISS/DisProt_v1.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "Zc5IeaTI5Vtw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary for important data from DisProt\n",
        "disorder_start_and_end = {}\n",
        "\n",
        "for i, acc in enumerate(data_disprot['acc']):\n",
        "  s = data_disprot['start'][i]\n",
        "  e = data_disprot['end'][i]\n",
        "  arr = disorder_start_and_end.get((str(acc)), [])\n",
        "\n",
        "  if (s, e) not in arr:\n",
        "    disorder_start_and_end[str(acc)] = arr + [(s, e)]\n"
      ],
      "metadata": {
        "id": "xG6dyQnBKQLg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new table for important DisProt data\n",
        "data = {'acc': disorder_start_and_end.keys(), 'disordered_regions': disorder_start_and_end.values()}"
      ],
      "metadata": {
        "id": "moNeeyrlMpc8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(data)"
      ],
      "metadata": {
        "id": "CZ7zmVQONJao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "49dcdc07-063e-42c9-c9a3-01c03f3d898e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             acc                                disordered_regions\n",
              "0         P03265                          [(294, 334), (454, 464)]\n",
              "1         P49913                                      [(134, 170)]\n",
              "2         P03045            [(1, 107), (1, 22), (34, 47), (1, 36)]\n",
              "3         P00004                              [(1, 104), (2, 105)]\n",
              "4         P27695             [(1, 42), (1, 36), (32, 43), (2, 40)]\n",
              "...          ...                                               ...\n",
              "2414  A0A5P2U9X4  [(350, 525), (460, 521), (417, 426), (450, 525)]\n",
              "2415      P40939                                      [(637, 647)]\n",
              "2416      Q6CSX2                                      [(562, 831)]\n",
              "2417      Q8IYT8                                      [(168, 177)]\n",
              "2418      Q9UHK0                                      [(486, 495)]\n",
              "\n",
              "[2419 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a65816f3-9f97-4a6c-a449-33c3637ab0cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>disordered_regions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P03265</td>\n",
              "      <td>[(294, 334), (454, 464)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P49913</td>\n",
              "      <td>[(134, 170)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P03045</td>\n",
              "      <td>[(1, 107), (1, 22), (34, 47), (1, 36)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P00004</td>\n",
              "      <td>[(1, 104), (2, 105)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P27695</td>\n",
              "      <td>[(1, 42), (1, 36), (32, 43), (2, 40)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>A0A5P2U9X4</td>\n",
              "      <td>[(350, 525), (460, 521), (417, 426), (450, 525)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>P40939</td>\n",
              "      <td>[(637, 647)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>Q6CSX2</td>\n",
              "      <td>[(562, 831)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2417</th>\n",
              "      <td>Q8IYT8</td>\n",
              "      <td>[(168, 177)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2418</th>\n",
              "      <td>Q9UHK0</td>\n",
              "      <td>[(486, 495)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2419 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a65816f3-9f97-4a6c-a449-33c3637ab0cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a65816f3-9f97-4a6c-a449-33c3637ab0cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a65816f3-9f97-4a6c-a449-33c3637ab0cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_data = pd.DataFrame.from_dict(data)"
      ],
      "metadata": {
        "id": "2zdirGSM1mLG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proteins in this dataframe are preprocessed to get their full sequences from UniProt."
      ],
      "metadata": {
        "id": "UgikDmCOs6pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing - download all sequences.\n",
        "def preprocess_sequences(pandas_data):\n",
        "  protSeqDict = {}\n",
        "  for row in range(len(pandas_data)):\n",
        "    acc = pandas_data['acc'].loc[row]\n",
        "\n",
        "    url = f'https://www.uniprot.org/uniprotkb/{str(acc)}.fasta'\n",
        "    uniprot_fasta = requests.get(url).text\n",
        "    # Gets the sequence as a string of amino acids\n",
        "    protein_sequence = uniprot_fasta.split('\\n')[1:]\n",
        "    protein_sequence = ''.join(protein_sequence)\n",
        "\n",
        "    if protein_sequence == '':\n",
        "      continue\n",
        "\n",
        "    protSeqDict[acc] = protein_sequence\n",
        "  return protSeqDict\n",
        "\n",
        "protein_sequences_n_ids = preprocess_sequences(pandas_data)"
      ],
      "metadata": {
        "id": "__HLboQMkuC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/DL-DISS/uniSeqData.txt', 'wb') as outfile:\n",
        "    pickle.dump(protein_sequences_n_ids, outfile)"
      ],
      "metadata": {
        "id": "zeWa776Z6oCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick access to preprocessed data, instead of downloading it each time Notebook is opened."
      ],
      "metadata": {
        "id": "Es5pCp8KeX4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/DL-DISS/uniSeqData.txt', 'rb') as infile:\n",
        "    protein_sequences_n_ids = pickle.load(infile)"
      ],
      "metadata": {
        "id": "BfOrcmCH7mpr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing protein data that is incompatible with my solution."
      ],
      "metadata": {
        "id": "rLif_xOQeo_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_pandas_data = pandas_data\n",
        "x = protein_sequences_n_ids.keys()\n",
        "for acc in pandas_data['acc']:\n",
        "  if acc in x:\n",
        "    continue\n",
        "  else:\n",
        "    index_to_drop = clean_pandas_data[clean_pandas_data['acc'] == acc].index.tolist()[0]\n",
        "    clean_pandas_data = clean_pandas_data.drop(index_to_drop)"
      ],
      "metadata": {
        "id": "hBSpgSf24pev"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in clean_pandas_data['acc']:\n",
        "  seqq = protein_sequences_n_ids.get(acc)\n",
        "  if 'X' in seqq or 'U' in seqq or 'Z' in seqq:\n",
        "    index_to_drop = clean_pandas_data[clean_pandas_data['acc'] == acc].index.tolist()[0]\n",
        "    clean_pandas_data = clean_pandas_data.drop(index_to_drop)\n",
        "\n",
        "print(len(clean_pandas_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSnFFs37mo3",
        "outputId": "b093403f-7657-4603-98fd-568b8675fc54"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = {'acc': (clean_pandas_data['acc'].tolist()), 'disordered_regions': (clean_pandas_data['disordered_regions'].tolist())}\n",
        "fully_clean_pandas_data = pd.DataFrame.from_dict(clean_data)"
      ],
      "metadata": {
        "id": "ztRDb1LuMWHQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset class for our data. \n",
        "- Takes in pandas data (usually full TSV).\n",
        "- The amino acid vectorising map.\n",
        "- A dictionary mapping protein accession numbers to their sequence (generated from preprocessing)."
      ],
      "metadata": {
        "id": "79WpGfwSqHFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisProtDataset(Dataset):\n",
        "    def __init__(self, pandas_table, amino_map, protein_sequences, transform=None):\n",
        "        self.disorder_prot = pandas_table\n",
        "        self.sequence_map = make_image\n",
        "        self.sequences = protein_sequences\n",
        "        self.tranform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.disorder_prot)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Protein accession number - key identifier\n",
        "        acc = self.disorder_prot['acc'].loc[idx]\n",
        "        idrs = self.disorder_prot['disordered_regions'].loc[idx]\n",
        "        \n",
        "        # Get sequence\n",
        "        protein_sequence = self.sequences.get(acc)\n",
        "        # Vectorise amino acids\n",
        "        protein_sequence_image = self.sequence_map(protein_sequence)\n",
        "        # Converts channel dictionary to 2D array\n",
        "        protein_sequence_image = np.array(list(protein_sequence_image.values()))\n",
        "        \n",
        "        # Create order/disorder label\n",
        "        disorder_label = np.zeros(len(protein_sequence))\n",
        "        for (start, end) in idrs:\n",
        "          disorder_label[start-1:end] = 1\n",
        "\n",
        "        get_dict = {'acc': acc, 'image': protein_sequence_image, 'label': disorder_label}\n",
        "        return get_dict"
      ],
      "metadata": {
        "id": "2hbU6qcbknvs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiates instance variable of DisProtDataset class\n",
        "formed_dataset_class = DisProtDataset(fully_clean_pandas_data, make_image, protein_sequences_n_ids)"
      ],
      "metadata": {
        "id": "jwhnoilg1RaT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can test output of class\n",
        "formed_dataset_class[0]"
      ],
      "metadata": {
        "id": "Nz-nheMD1Xsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25bf4da-a60e-4eac-b9f0-d42282a5d444"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 'P03265', 'image': array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]), 'label': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(formed_dataset_class[0].get('image')).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7IbYflr_EXu",
        "outputId": "54f1ecf8-3ceb-48b9-d877-fb0805b98113"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 529)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dataloader using the instance variable."
      ],
      "metadata": {
        "id": "tlP1hljAq-za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(formed_dataset_class, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "# Check data loaded\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch)\n",
        "    print(sample_batched)\n",
        "    # observe 4th batch and stop.\n",
        "    if i_batch == 3:\n",
        "        break"
      ],
      "metadata": {
        "id": "8BFbZ3We8Dk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423893dc-efd2-40e8-c72f-42f2919e4108"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "{'acc': ['P32628'], 'image': tensor([[[0., 0., 0.,  ..., 0., 1., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
            "         ...,\n",
            "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0.]], dtype=torch.float64)}\n",
            "1\n",
            "{'acc': ['P01252'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 1.,  ..., 0., 1., 1.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1.]], dtype=torch.float64)}\n",
            "2\n",
            "{'acc': ['Q9UBW5'], 'image': tensor([[[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)}\n",
            "3\n",
            "{'acc': ['P19599'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creates a data iterator.\n",
        "- This is similar to the dataloader.\n",
        "- After the item has been used it is removed from the 'iterator'.\n",
        "- Can randomly shuffle items about. But removes them after used, so doesn't accidentally repeat sequences."
      ],
      "metadata": {
        "id": "Im_Pi-b9tcpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing how to get samples from dataloader using dataiter\n",
        "dataiter = iter(dataloader)\n",
        "for i, sam in enumerate(dataiter):\n",
        "  print(sam)\n",
        "  if i == 2:\n",
        "    break\n",
        "\n",
        "acc, image, label = next(dataiter).values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHoNNB8GG8Rq",
        "outputId": "5bc1a512-e1c2-4cca-b2fd-2b4961c88659"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'acc': ['P14602'], 'image': tensor([[[0., 0., 0.,  ..., 0., 1., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)}\n",
            "{'acc': ['Q03518'], 'image': tensor([[[0., 1., 0.,  ..., 1., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)}\n",
            "{'acc': ['Q02548'], 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 1., 0.,  ..., 1., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), 'label': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "       dtype=torch.float64)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with a PyTorch NN. FCN model"
      ],
      "metadata": {
        "id": "sXw_YBXOohYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses 1D Convolution kernels\n",
        "\n",
        "model = nn.Sequential(collections.OrderedDict([\n",
        "          ('conv1', nn.Conv1d(20, 10, 21, padding=10)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('conv2', nn.Conv1d(10, 10, 21, padding=10)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('conv3', nn.Conv1d(10, 1, 21, padding=10)),\n",
        "          ('sig1', nn.Sigmoid())\n",
        "        ]))"
      ],
      "metadata": {
        "id": "fUYOZvHI460D"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model, given DisProt dataset"
      ],
      "metadata": {
        "id": "NAQwoAkAwOQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate train/validation/test datasets. Currently using a 60/20/20 in place split from generated pandas data."
      ],
      "metadata": {
        "id": "LVya_gCvf8Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = round(len(fully_clean_pandas_data) * (60/100))\n",
        "train_pandas_data = fully_clean_pandas_data[0:train_len]\n",
        "train_dataset = DisProtDataset(train_pandas_data, make_image, protein_sequences_n_ids)\n",
        "\n",
        "valid_len = round((len(fully_clean_pandas_data) * (20/100)))\n",
        "valid_pandas_data = fully_clean_pandas_data[train_len:(train_len+valid_len)]\n",
        "# Reset index helps clean up index column after slicing.\n",
        "valid_pandas_data = valid_pandas_data.reset_index(drop=True)\n",
        "validation_dataset = DisProtDataset(valid_pandas_data, make_image, protein_sequences_n_ids)\n",
        "\n",
        "test_len = len(fully_clean_pandas_data) - (train_len + valid_len)\n",
        "test_pandas_data = fully_clean_pandas_data[(train_len+valid_len):]\n",
        "test_pandas_data = test_pandas_data.reset_index(drop=True)\n",
        "test_dataset = DisProtDataset(test_pandas_data, make_image, protein_sequences_n_ids)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1,\n",
        "                        shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "idlEpTV1eASB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "epoch_print_gap = 20\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    #model = model.to(device)\n",
        "    for epoch in range(0, n_epochs):\n",
        "        \n",
        "        running_loss_train = 0.0\n",
        "        total_epoch_loss = 0.0\n",
        "\n",
        "        # Creating an iterator jumbles the sequences order, so each accumulated batch will consider different \n",
        "        # sequences over many epochs\n",
        "        train_iter = iter(train_loader)\n",
        "\n",
        "        # Where i is a counter and sam is a dictionary\n",
        "        for i, sam in enumerate(train_iter):\n",
        "          acc, image, label = sam.values() #sam['acc'], sam['image'], sam['label']\n",
        "          NN_input = image.type(torch.FloatTensor)\n",
        "          expected_output = label.type(torch.FloatTensor)\n",
        "\n",
        "          output = model(NN_input)\n",
        "          squeezed_o = torch.squeeze(output)\n",
        "          squeezed_e_o = torch.squeeze(expected_output)\n",
        "\n",
        "          loss = loss_fn(squeezed_o, squeezed_e_o)          \n",
        "          loss.backward()\n",
        "          running_loss_train += loss.item()\n",
        "          total_epoch_loss += loss.item()\n",
        "\n",
        "          # This has effect of batches of size 16.\n",
        "          # Don't have just i as when i is 0, this is true, therefore use i+1 and divisor 17.\n",
        "          if (i+1) % 17 == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "          \n",
        "          # Print loss throughout epoch.\n",
        "          # Shows loss per 400 sequences of each epoch.\n",
        "          # Only prints on print gap\n",
        "          if epoch % epoch_print_gap == 0:\n",
        "            if (i+1) % 400 == 0:\n",
        "              print(\"Epoch: \"+str(epoch), end=\" \")\n",
        "              # Average loss over these 400 sequences\n",
        "              print(\"Current loss: \"+str(running_loss_train / 400))\n",
        "              running_loss_train = 0.0\n",
        "\n",
        "        # Separates printed epochs\n",
        "        if epoch == 0 or epoch % epoch_print_gap == 0:\n",
        "            print(\"Epoch\", epoch, \"Done \\n\\n\")\n",
        "\n",
        "        epoch_loss_arr.append( (total_epoch_loss / len(train_loader)) )\n",
        "\n",
        "# Main\n",
        "lamb=0.001    # L2 weight decay term\n",
        "lr = 0.001\n",
        "epochs = 100\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=lamb) # This is adding L2 regularisation with factor lamb to every parameter\n",
        "\n",
        "epoch_loss_arr = []\n",
        "training_loop(epochs, optimizer, model, criterion, train_loader)\n"
      ],
      "metadata": {
        "id": "JJWE6Ul0Yy9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe5cb2c-0c3b-425e-b956-41361bcfc58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Current loss: 0.6503472909331321\n",
            "Epoch: 0 Current loss: 0.6283927296847105\n",
            "Epoch: 0 Current loss: 0.6275629050284625\n",
            "Epoch 0 Done \n",
            "\n",
            "\n",
            "Epoch: 20 Current loss: 0.5033897900208831\n",
            "Epoch: 20 Current loss: 0.4935393209662288\n",
            "Epoch: 20 Current loss: 0.5035745454579592\n",
            "Epoch 20 Done \n",
            "\n",
            "\n",
            "Epoch: 40 Current loss: 0.4501248649135232\n",
            "Epoch: 40 Current loss: 0.39770716879051177\n",
            "Epoch: 40 Current loss: 0.3814727908070199\n",
            "Epoch 40 Done \n",
            "\n",
            "\n",
            "Epoch: 60 Current loss: 0.3270174062298611\n",
            "Epoch: 60 Current loss: 0.3520899317320436\n",
            "Epoch: 60 Current loss: 0.3362581029650755\n",
            "Epoch 60 Done \n",
            "\n",
            "\n",
            "Epoch: 80 Current loss: 0.34181133256759494\n",
            "Epoch: 80 Current loss: 0.31887896386673675\n",
            "Epoch: 80 Current loss: 0.3095180692523718\n",
            "Epoch 80 Done \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotted training loss\n",
        "\n",
        "plt.plot(range(100), epoch_loss_arr)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "92hjl9BDn171",
        "outputId": "1cfbc105-02c6-4337-b070-688bacea2e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing using test data and trained model"
      ],
      "metadata": {
        "id": "-mYEs1_IRjjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing a single test sequence and labelling this based on probabilities generated by model.\n",
        "test_iter = iter(test_loader)\n",
        "_, im, real_lab = next(test_iter).values()\n",
        "print(im)\n",
        "im = im.type(torch.FloatTensor)\n",
        "outputs_pred = model(im)\n",
        "print(outputs_pred)\n",
        "\n",
        "pred_lab = []\n",
        "\n",
        "outputs_pred = torch.squeeze(outputs_pred)\n",
        "for val in outputs_pred:\n",
        "  if val > 0.5:\n",
        "    pred_lab.append(1)\n",
        "  else:\n",
        "    pred_lab.append(0)\n",
        "\n",
        "print(np.array(pred_lab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujAlILL3gZKZ",
        "outputId": "62d1d8b6-5d69-4d31-ffa4-765ccb76e013"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 1., 0.]]], dtype=torch.float64)\n",
            "tensor([[[7.9686e-01, 8.4878e-01, 8.8898e-01, 8.3581e-01, 8.1768e-01,\n",
            "          8.1467e-01, 7.8606e-01, 7.8799e-01, 8.3301e-01, 8.6333e-01,\n",
            "          9.1999e-01, 9.2831e-01, 9.2089e-01, 9.3371e-01, 9.4908e-01,\n",
            "          9.4807e-01, 9.2725e-01, 9.2557e-01, 8.9405e-01, 8.9806e-01,\n",
            "          9.1498e-01, 8.9225e-01, 8.3980e-01, 7.3481e-01, 7.5613e-01,\n",
            "          7.6560e-01, 7.1958e-01, 7.8299e-01, 7.6456e-01, 7.4866e-01,\n",
            "          7.4915e-01, 7.5357e-01, 7.5774e-01, 8.2598e-01, 8.1899e-01,\n",
            "          8.0277e-01, 8.0951e-01, 8.5550e-01, 8.6194e-01, 8.7729e-01,\n",
            "          8.3019e-01, 6.8730e-01, 7.8416e-01, 8.4297e-01, 9.1731e-01,\n",
            "          9.3065e-01, 9.3245e-01, 9.5755e-01, 9.4753e-01, 9.2438e-01,\n",
            "          9.1285e-01, 9.2929e-01, 8.9643e-01, 8.6779e-01, 8.6579e-01,\n",
            "          8.3034e-01, 8.2427e-01, 8.2361e-01, 8.3192e-01, 8.2445e-01,\n",
            "          7.8783e-01, 8.2659e-01, 8.6594e-01, 8.5479e-01, 8.7577e-01,\n",
            "          8.8712e-01, 8.6750e-01, 8.8950e-01, 8.9156e-01, 8.9993e-01,\n",
            "          8.5810e-01, 8.7736e-01, 8.7889e-01, 8.7372e-01, 8.8333e-01,\n",
            "          8.8619e-01, 9.0961e-01, 9.0009e-01, 9.0169e-01, 9.2577e-01,\n",
            "          8.7315e-01, 9.1071e-01, 8.5270e-01, 7.6695e-01, 6.6650e-01,\n",
            "          5.6899e-01, 5.8551e-01, 5.8867e-01, 5.6133e-01, 5.8153e-01,\n",
            "          6.0368e-01, 6.4140e-01, 4.7522e-01, 4.8051e-01, 4.2322e-01,\n",
            "          4.2135e-01, 4.9895e-01, 3.8231e-01, 3.3017e-01, 2.9881e-01,\n",
            "          2.3161e-01, 2.8496e-01, 1.9938e-01, 2.1833e-01, 1.5723e-01,\n",
            "          1.2771e-01, 1.2140e-01, 1.3891e-01, 1.3918e-01, 1.3180e-01,\n",
            "          1.2192e-01, 1.1694e-01, 8.2884e-02, 7.1721e-02, 6.3532e-02,\n",
            "          5.7738e-02, 5.4347e-02, 5.3513e-02, 5.4233e-02, 4.3559e-02,\n",
            "          2.9318e-02, 4.4918e-02, 4.8510e-02, 8.3005e-02, 7.8583e-02,\n",
            "          7.4425e-02, 8.4085e-02, 6.4560e-02, 5.8833e-02, 5.8138e-02,\n",
            "          4.4743e-02, 4.7525e-02, 5.0734e-02, 6.1646e-02, 6.6356e-02,\n",
            "          8.2061e-02, 8.2720e-02, 1.0662e-01, 8.8418e-02, 6.5059e-02,\n",
            "          4.7696e-02, 4.1964e-02, 3.9125e-02, 3.0486e-02, 2.1275e-02,\n",
            "          2.0385e-02, 2.1125e-02, 2.2145e-02, 1.9377e-02, 1.6474e-02,\n",
            "          1.6045e-02, 1.6509e-02, 1.3476e-02, 1.0514e-02, 7.0670e-03,\n",
            "          4.9522e-03, 3.4524e-03, 3.1451e-03, 1.9219e-03, 8.2569e-04,\n",
            "          1.0790e-03, 1.2675e-03, 1.1584e-03, 7.8318e-04, 5.5301e-04,\n",
            "          6.0460e-04, 5.3047e-04, 6.9732e-04, 5.2658e-04, 3.0110e-04,\n",
            "          2.3459e-04, 1.4603e-04, 1.1586e-04, 1.5795e-04, 9.9180e-05,\n",
            "          1.4281e-04, 1.6643e-04, 1.6352e-04, 1.7928e-04, 1.7350e-04,\n",
            "          2.7646e-04, 5.5857e-04, 6.9118e-04, 9.8557e-04, 1.4028e-03,\n",
            "          2.1425e-03, 2.6233e-03, 3.5023e-03, 3.1587e-03, 2.6849e-03,\n",
            "          8.9933e-03, 9.3121e-03, 1.8148e-02, 1.7213e-02, 1.6798e-02,\n",
            "          2.7518e-02, 2.0139e-02, 1.9454e-02, 2.9258e-02, 3.5636e-02,\n",
            "          6.4811e-02, 8.5421e-02, 9.6373e-02, 1.1785e-01, 8.3245e-02,\n",
            "          6.1584e-02, 1.0211e-01, 9.4375e-02, 1.1214e-01, 1.1941e-01,\n",
            "          2.3244e-01, 1.9232e-01, 2.1177e-01, 1.7436e-01, 1.9690e-01,\n",
            "          2.3848e-01, 1.6190e-01, 1.2398e-01, 1.2213e-01, 8.2776e-02,\n",
            "          6.6872e-02, 9.5721e-02, 9.1258e-02, 1.0185e-01, 8.5706e-02,\n",
            "          3.3991e-02, 2.3025e-02, 2.0592e-02, 2.3911e-02, 1.8245e-02,\n",
            "          2.0171e-02, 1.8977e-02, 1.7424e-02, 2.3451e-02, 3.1901e-02,\n",
            "          5.2809e-02, 9.2465e-02, 9.2742e-02, 6.4469e-02, 6.5664e-02,\n",
            "          7.0609e-02, 8.3385e-02, 9.2990e-02, 1.2539e-01, 1.1903e-01,\n",
            "          1.2961e-01, 1.2391e-01, 1.0189e-01, 8.7906e-02, 8.5491e-02,\n",
            "          1.0228e-01, 9.2921e-02, 7.9869e-02, 5.7216e-02, 2.9162e-02,\n",
            "          2.1386e-02, 1.2640e-02, 9.3906e-03, 7.8161e-03, 7.0200e-03,\n",
            "          5.5870e-03, 4.0430e-03, 2.3470e-03, 2.8505e-03, 3.1035e-03,\n",
            "          3.9992e-03, 5.6567e-03, 5.6101e-03, 3.2401e-03, 2.4334e-03,\n",
            "          2.4832e-03, 1.9547e-03, 1.2895e-03, 9.7772e-04, 1.5222e-03,\n",
            "          1.2002e-03, 1.2273e-03, 1.3600e-03, 8.8014e-04, 9.8906e-04,\n",
            "          1.0688e-03, 1.1310e-03, 1.4003e-03, 1.7857e-03, 4.3272e-03,\n",
            "          7.3622e-03, 8.8319e-03, 1.0340e-02, 6.1792e-03, 8.5994e-03,\n",
            "          1.0681e-02, 1.3365e-02, 2.0137e-02, 2.9338e-02, 6.9518e-02,\n",
            "          5.8378e-02, 9.0850e-02, 7.3421e-02, 7.3919e-02, 1.2509e-01,\n",
            "          1.1528e-01, 1.3204e-01, 1.3060e-01, 1.3407e-01, 7.6762e-02,\n",
            "          5.0653e-02, 3.7273e-02, 3.1588e-02, 3.1767e-02, 3.3307e-02,\n",
            "          5.3585e-02, 4.6981e-02, 4.4151e-02, 4.6425e-02, 4.5123e-02,\n",
            "          4.9552e-02, 4.1741e-02, 4.1543e-02, 3.7924e-02, 6.4219e-02,\n",
            "          3.7244e-02, 3.8918e-02, 2.7820e-02, 2.0509e-02, 1.4835e-02,\n",
            "          6.3266e-03, 5.4854e-03, 3.4726e-03, 4.3930e-03, 4.0665e-03,\n",
            "          3.6721e-03, 2.8397e-03, 2.6144e-03, 2.3071e-03, 1.6151e-03,\n",
            "          1.5712e-03, 1.6655e-03, 1.9659e-03, 1.8810e-03, 2.1825e-03,\n",
            "          3.4698e-03, 4.4724e-03, 3.8392e-03, 5.4544e-03, 4.8759e-03,\n",
            "          3.8805e-03, 4.4114e-03, 3.7767e-03, 4.4330e-03, 5.0077e-03,\n",
            "          6.6501e-03, 5.4239e-03, 4.6060e-03, 4.7604e-03, 4.5109e-03,\n",
            "          3.3475e-03, 3.0060e-03, 2.8955e-03, 3.8182e-03, 5.7016e-03,\n",
            "          4.6884e-03, 3.5573e-03, 4.7125e-03, 1.1200e-02, 1.4969e-02,\n",
            "          2.2187e-02, 5.0848e-02, 1.0065e-01, 1.6743e-01, 1.3039e-01,\n",
            "          1.2098e-01, 1.2736e-01, 1.8314e-01, 1.8544e-01, 2.4368e-01,\n",
            "          2.7322e-01, 2.7214e-01, 2.3197e-01, 2.7446e-01, 2.1599e-01,\n",
            "          1.8625e-01, 1.6969e-01, 2.5142e-01, 2.8916e-01, 2.4391e-01,\n",
            "          1.4169e-01, 1.2402e-01, 1.3333e-01, 6.9780e-02, 5.4117e-02,\n",
            "          4.1705e-02, 5.0884e-02, 9.1267e-02, 7.1115e-02, 5.7685e-02,\n",
            "          4.3325e-02, 4.1690e-02, 2.8250e-02, 2.2269e-02, 1.1553e-02,\n",
            "          8.5632e-03, 8.0750e-03, 6.6024e-03, 4.6413e-03, 1.6234e-03,\n",
            "          9.9310e-04, 8.9591e-04, 7.6305e-04, 5.7691e-04, 4.1381e-04,\n",
            "          2.9592e-04, 3.5531e-04, 4.3598e-04, 4.9648e-04, 5.6113e-04,\n",
            "          6.9154e-04, 6.7811e-04, 9.1338e-04, 9.4301e-04, 7.5080e-04,\n",
            "          8.3039e-04, 1.0287e-03, 1.0497e-03, 1.3207e-03, 1.4097e-03,\n",
            "          2.5390e-03, 5.6967e-03, 8.0128e-03, 7.8819e-03, 7.9390e-03,\n",
            "          8.2129e-03, 1.4515e-02, 1.9297e-02, 2.5869e-02, 1.9529e-02,\n",
            "          2.1949e-02, 2.6128e-02, 2.6966e-02, 2.8191e-02, 2.6110e-02,\n",
            "          2.5414e-02, 2.8836e-02, 2.2250e-02, 2.6377e-02, 1.9935e-02,\n",
            "          2.2681e-02, 2.2274e-02, 1.8863e-02, 1.4437e-02, 1.7512e-02,\n",
            "          2.3758e-02, 1.9432e-02, 1.6534e-02, 1.1025e-02, 7.1876e-03,\n",
            "          6.0027e-03, 5.2781e-03, 5.0190e-03, 5.8186e-03, 5.8360e-03,\n",
            "          6.7944e-03, 8.1373e-03, 6.3848e-03, 7.2582e-03, 8.1579e-03,\n",
            "          8.5948e-03, 7.8706e-03, 7.3130e-03, 7.4986e-03, 8.5199e-03,\n",
            "          7.6863e-03, 6.7991e-03, 4.6899e-03, 4.1891e-03, 3.8449e-03,\n",
            "          4.5900e-03, 6.5653e-03, 5.6549e-03, 5.8807e-03, 4.9018e-03,\n",
            "          6.0351e-03, 7.6346e-03, 9.4190e-03, 9.5238e-03, 8.9526e-03,\n",
            "          9.5485e-03, 5.8920e-03, 7.4337e-03, 6.0436e-03, 8.1822e-03,\n",
            "          7.1762e-03, 5.1413e-03, 4.6332e-03, 5.0516e-03, 5.4846e-03,\n",
            "          6.1714e-03, 7.7663e-03, 6.6014e-03, 5.3605e-03, 4.9388e-03,\n",
            "          5.3849e-03, 7.0815e-03, 8.1043e-03, 8.5027e-03, 7.9004e-03,\n",
            "          9.3411e-03, 7.7719e-03, 1.1238e-02, 1.0849e-02, 1.1828e-02,\n",
            "          1.4173e-02, 1.4711e-02, 1.7154e-02, 1.6917e-02, 1.6851e-02,\n",
            "          2.0088e-02, 1.4368e-02, 1.5301e-02, 1.4349e-02, 1.9675e-02,\n",
            "          3.8750e-02, 5.7655e-02, 8.6774e-02, 7.4408e-02, 1.2372e-01,\n",
            "          1.0470e-01, 1.3041e-01, 1.7072e-01, 1.7915e-01, 2.2716e-01,\n",
            "          2.5889e-01, 2.4782e-01, 2.8397e-01, 2.7666e-01, 2.6986e-01,\n",
            "          2.8418e-01, 2.4554e-01, 2.8068e-01, 2.7786e-01, 2.6974e-01,\n",
            "          2.6151e-01, 2.5820e-01, 2.6112e-01, 2.0991e-01, 2.3486e-01,\n",
            "          1.2183e-01, 1.5560e-01, 1.8297e-01, 1.9034e-01, 1.6905e-01,\n",
            "          1.2976e-01, 8.1308e-02, 9.3859e-02, 1.0713e-01, 9.9308e-02,\n",
            "          9.5108e-02, 7.7104e-02, 8.4153e-02, 5.1238e-02, 3.1173e-02,\n",
            "          6.0144e-02, 5.9170e-02, 6.2610e-02, 5.6078e-02, 7.0411e-02,\n",
            "          3.3422e-02, 5.7272e-02, 6.6029e-02, 8.1460e-02, 5.1142e-02,\n",
            "          8.6203e-02, 8.0553e-02, 1.0152e-01, 1.1301e-01, 1.1929e-01,\n",
            "          1.4434e-01, 2.1433e-01, 2.6547e-01, 2.9058e-01, 2.4642e-01,\n",
            "          3.5919e-01, 3.5366e-01, 2.6165e-01, 2.2449e-01, 2.0280e-01,\n",
            "          1.3389e-01, 1.9607e-01, 1.2015e-01, 9.9789e-02, 1.0495e-01,\n",
            "          2.0129e-01, 2.1306e-01, 1.8879e-01, 1.8187e-01, 2.0326e-01,\n",
            "          2.4276e-01, 1.9047e-01, 2.1747e-01, 2.4449e-01, 2.3256e-01,\n",
            "          2.9689e-01, 2.9090e-01, 3.6126e-01, 3.6247e-01, 4.3223e-01,\n",
            "          4.3965e-01, 4.9523e-01, 4.4187e-01, 4.6946e-01, 4.6846e-01,\n",
            "          4.9062e-01, 5.0504e-01, 5.0106e-01, 5.5194e-01, 3.9136e-01,\n",
            "          3.6790e-01, 3.1874e-01, 3.3232e-01, 3.3273e-01, 3.0255e-01,\n",
            "          3.3535e-01, 3.6404e-01, 3.7885e-01, 4.1798e-01, 4.3289e-01,\n",
            "          5.5721e-01, 5.5905e-01, 5.6186e-01, 4.9653e-01, 4.2914e-01,\n",
            "          4.1105e-01, 4.1794e-01, 3.8170e-01, 3.5283e-01, 2.8708e-01,\n",
            "          2.7267e-01]]], grad_fn=<SigmoidBackward0>)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
            " 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating similarity over entire test dataset."
      ],
      "metadata": {
        "id": "D4RvfKXPS72B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsure if this check similarity function is correct.\n",
        "def check_similarity(gen, true):\n",
        "  gen = torch.squeeze(gen)\n",
        "  custom_lab = []\n",
        "  for val in gen:\n",
        "    if val > 0.5:\n",
        "      custom_lab.append(1)\n",
        "    else:\n",
        "      custom_lab.append(0)\n",
        "  \n",
        "  # This checks every amino acid. I could also check if the disorder predictions were correct and what ratio this gives.\n",
        "  total_pred_right = 0\n",
        "  for i, value in enumerate(torch.squeeze(true)):\n",
        "    if value == custom_lab[i]:\n",
        "      total_pred_right += 1\n",
        "  \n",
        "  ratio_right = total_pred_right / len(custom_lab)\n",
        "  return ratio_right\n",
        "\n",
        "with torch.no_grad():\n",
        "  similarity_sum = 0\n",
        "  for test_seq in test_loader:\n",
        "    input_seq = test_seq.get('image')\n",
        "    input_seq = input_seq.type(torch.FloatTensor)\n",
        "    true_label = test_seq.get('label')\n",
        "\n",
        "    output_label = model(input_seq)\n",
        "    similarity_sum += check_similarity(output_label, true_label)\n",
        "\n",
        "  right_percentage = similarity_sum / len(test_loader)"
      ],
      "metadata": {
        "id": "9Rbjx4mq2b3y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "right_percentage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZEdVPz3SOId",
        "outputId": "a9c35c49-279c-49a1-8c87-571c95b7016a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8003953115893218"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving model - for later use."
      ],
      "metadata": {
        "id": "zEPD-11xTDsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Writes trained model to storage\n",
        "\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/DL-DISS/cnn_net.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "sXqdpXNV5qe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To reload the model back in, this class was created and instantiated so that the state dictionary of the model could be loaded.\n",
        "\n",
        "class FCN_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(20, 10, 21, padding=10)\n",
        "        self.conv2 = nn.Conv1d(10, 10, 21, padding=10)\n",
        "        self.conv3 = nn.Conv1d(10, 1, 21, padding=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.sigmoid(self.conv3(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "BSRlagUA9D6w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reads trained model from storage\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/DL-DISS/cnn_net.pth'\n",
        "\n",
        "loaded_model = FCN_Net()\n",
        "loaded_model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e84RuBaW6oq4",
        "outputId": "c1e30082-93c4-4cd4-f1e7-6d683148497d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21iZSlCo8mvN",
        "outputId": "41d1e989-fd71-4c4d-cf8c-3d1fc0552535"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FCN_Net(\n",
              "  (conv1): Conv1d(20, 10, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              "  (conv2): Conv1d(10, 10, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              "  (conv3): Conv1d(10, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing a single protein sequence. This will be useful to understand the models behaviour when given a single sequence to predict."
      ],
      "metadata": {
        "id": "IwZ_vDUTWuoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_single_seq_to_test_loaded_model():\n",
        "  \n",
        "  acc, vectorised_image, true_label = formed_dataset_class[0].values()\n",
        "  vectorised_image = torch.tensor(vectorised_image)\n",
        "  vectorised_image = vectorised_image.type(torch.FloatTensor)\n",
        "  true_label = torch.tensor(true_label)\n",
        "  true_label = true_label.type(torch.FloatTensor)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    predicted_label = loaded_model(vectorised_image)\n",
        "\n",
        "  pred_lab = []\n",
        "  predicted_label = torch.squeeze(predicted_label)\n",
        "  for val in predicted_label:\n",
        "    if val > 0.5:\n",
        "      pred_lab.append(1)\n",
        "    else:\n",
        "      pred_lab.append(0)\n",
        "\n",
        "  print(np.array(pred_lab))  "
      ],
      "metadata": {
        "id": "mgromFRtTxoF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_single_seq_to_test_loaded_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DII3A_5CT7ID",
        "outputId": "d1df0a80-d2d6-4682-de97-864433c2b135"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file below can be used with an external Python file, then with the Django webapp to ensure the planned process works."
      ],
      "metadata": {
        "id": "AuAsRddTXMwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc, vectorised_image, true_label = formed_dataset_class[0].values()\n",
        "reusable_test_seq = {'vector_seq' : vectorised_image, 'true_label' : true_label}\n",
        "with open('/content/drive/My Drive/Colab Notebooks/DL-DISS/singleSeqTest.txt', 'wb') as outfile:\n",
        "    pickle.dump(reusable_test_seq, outfile)"
      ],
      "metadata": {
        "id": "GxeWHy0MW6kb"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/DL-DISS/singleSeqTest.txt', 'rb') as infile:\n",
        "    single_test_seq_loaded = pickle.load(infile)\n",
        "\n",
        "seq, lab = single_test_seq_loaded.values()\n",
        "seq = torch.tensor(seq)\n",
        "seq = seq.type(torch.FloatTensor)\n",
        "lab = torch.tensor(lab)\n",
        "lab = lab.type(torch.FloatTensor)\n",
        "\n",
        "with torch.no_grad():\n",
        "    predicted_label = loaded_model(seq)\n"
      ],
      "metadata": {
        "id": "umnu3yHYXj8C"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_vdSJ2zXlE8"
      },
      "execution_count": 68,
      "outputs": []
    }
  ]
}