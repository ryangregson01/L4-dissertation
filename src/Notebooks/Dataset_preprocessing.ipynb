{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxYEI4q6s3Fm"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import pandas as pd # For csv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data set-up"
      ],
      "metadata": {
        "id": "ebjZeL7Wu-rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import drive, so that read and write access can be used with processed files, speeding up workflow."
      ],
      "metadata": {
        "id": "8FElE8EiQhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2WcDvDHutzeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ddc97d-4751-4d3b-c6bd-f9160604cbd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading data from Disprot website\n",
        "- Disprot API had no clear way to download the full file of annotated disordered sequences.\n",
        "- Custom function uses URL from inspecting Disprots source code to download the TSV file.\n",
        "- Can change the release date and constraints on the documented sequences.\n",
        "- NB: TSV format and consensus false must remain to work with the rest of the processing steps.\n",
        "- Project has been done using the following:\n",
        " - year = '2022_06'\n",
        " - ambiguous = 'true'\n",
        " - obsolete = 'false'\n",
        " - format = 'tsv'\n",
        " - consensus = 'false'\n",
        "\n",
        "#### Creating a pandas dataframe containing accession IDs and disordered region locations.\n",
        "- This is used to generate labels for our disordered sequences."
      ],
      "metadata": {
        "id": "c7_KPDlHOgrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_disprot_dataset():\n",
        "  year = '2022_06'\n",
        "  ambiguous = 'true'\n",
        "  obsolete = 'false'\n",
        "  format = 'tsv'\n",
        "  # The rest of the processing only works if consensus is false. Assumes region file format.\n",
        "  consensus = 'false'\n",
        "\n",
        "  disprot_link = \"https://disprot.org/api/search?release=\"+year+\"&show_ambiguous=\"+ambiguous+\"&show_obsolete=\"+obsolete+\"&format=\"+format+\"&namespace=all&get_consensus=\"+consensus\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/downloaded_disprot_data.tsv', 'w') as outfile:\n",
        "    outfile.write( requests.get(disprot_link).text )\n",
        "\n",
        "  # Data from DisProt TSV - https://disprot.org/download\n",
        "  data_disprot = pd.read_csv('/content/drive/My Drive/Colab Notebooks/diss_files/downloaded_disprot_data.tsv', sep='\\t')\n",
        "  return data_disprot\n",
        "\n",
        "def create_dataframe_of_idrs(data_disprot):\n",
        "  # Dictionary for disordered region data from DisProt\n",
        "  disorder_start_and_end = {}\n",
        "  for i, acc in enumerate(data_disprot['acc']):\n",
        "    s = data_disprot['start'][i]\n",
        "    e = data_disprot['end'][i]\n",
        "    arr = disorder_start_and_end.get((str(acc)), [])\n",
        "    if (s, e) not in arr:\n",
        "      disorder_start_and_end[str(acc)] = arr + [(s, e)]\n",
        "      \n",
        "  # Create new table for important DisProt data\n",
        "  data = {'acc': disorder_start_and_end.keys(), 'disordered_regions': disorder_start_and_end.values()}\n",
        "  pandas_data = pd.DataFrame.from_dict(data)\n",
        "  return pandas_data\n"
      ],
      "metadata": {
        "id": "HMquOZ31Q0pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_disprot = get_disprot_dataset()\n",
        "pandas_data = create_dataframe_of_idrs(data_disprot)"
      ],
      "metadata": {
        "id": "CZ7zmVQONJao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_data"
      ],
      "metadata": {
        "id": "2zdirGSM1mLG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "ce668f69-7834-4624-f26b-136568ee72dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             acc                                disordered_regions\n",
              "0         P03265                          [(294, 334), (454, 464)]\n",
              "1         P49913                                      [(134, 170)]\n",
              "2         P03045            [(1, 107), (1, 22), (34, 47), (1, 36)]\n",
              "3         P00004                              [(1, 104), (2, 105)]\n",
              "4         P27695             [(1, 42), (1, 36), (32, 43), (2, 40)]\n",
              "...          ...                                               ...\n",
              "2414  A0A5P2U9X4  [(350, 525), (460, 521), (417, 426), (450, 525)]\n",
              "2415      P40939                                      [(637, 647)]\n",
              "2416      Q6CSX2                                      [(562, 831)]\n",
              "2417      Q8IYT8                                      [(168, 177)]\n",
              "2418      Q9UHK0                                      [(486, 495)]\n",
              "\n",
              "[2419 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a940ab3-0e92-4915-bc8b-d24849731153\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>disordered_regions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P03265</td>\n",
              "      <td>[(294, 334), (454, 464)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P49913</td>\n",
              "      <td>[(134, 170)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P03045</td>\n",
              "      <td>[(1, 107), (1, 22), (34, 47), (1, 36)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P00004</td>\n",
              "      <td>[(1, 104), (2, 105)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P27695</td>\n",
              "      <td>[(1, 42), (1, 36), (32, 43), (2, 40)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>A0A5P2U9X4</td>\n",
              "      <td>[(350, 525), (460, 521), (417, 426), (450, 525)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>P40939</td>\n",
              "      <td>[(637, 647)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>Q6CSX2</td>\n",
              "      <td>[(562, 831)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2417</th>\n",
              "      <td>Q8IYT8</td>\n",
              "      <td>[(168, 177)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2418</th>\n",
              "      <td>Q9UHK0</td>\n",
              "      <td>[(486, 495)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2419 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a940ab3-0e92-4915-bc8b-d24849731153')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a940ab3-0e92-4915-bc8b-d24849731153 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a940ab3-0e92-4915-bc8b-d24849731153');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading the full protein sequences.\n",
        "- Downloads these full sequences from UniProt.\n",
        " - If an empty string is returned this means the protein has been deprecated and we will not include this in our dataset.\n",
        "- Creates a dataframe"
      ],
      "metadata": {
        "id": "mYR0BZRiSrgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proteins in this dataframe are preprocessed to get their full sequences from UniProt."
      ],
      "metadata": {
        "id": "UgikDmCOs6pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sequences(pandas_data):\n",
        "  protSeqDict = {}\n",
        "  for row in range(len(pandas_data)):\n",
        "    acc = pandas_data['acc'].loc[row]\n",
        "\n",
        "    url = f'https://www.uniprot.org/uniprotkb/{str(acc)}.fasta'\n",
        "    uniprot_fasta = requests.get(url).text\n",
        "    # Gets the sequence as a string of amino acids\n",
        "    protein_sequence = uniprot_fasta.split('\\n')[1:]\n",
        "    protein_sequence = ''.join(protein_sequence)\n",
        "\n",
        "    if protein_sequence == '':\n",
        "      continue\n",
        "\n",
        "    protSeqDict[acc] = protein_sequence\n",
        "  return protSeqDict\n",
        "\n",
        "protein_sequences_n_ids = preprocess_sequences(pandas_data)"
      ],
      "metadata": {
        "id": "__HLboQMkuC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save preprocessed data\n",
        "def write_sequences():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/sequence_data.json', 'w') as outfile:\n",
        "    json.dump(protein_sequences_n_ids, outfile)\n",
        "\n",
        "# Quick access to preprocessed data, instead of downloading it each time Notebook is opened.\n",
        "def read_sequences():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/sequence_data.json', 'r') as infile:\n",
        "    return json.load(infile)\n",
        "\n",
        "# Commented out write sequences, so this file is not accidentally overwritten before preprocessing is ran\n",
        "#write_sequences()\n",
        "protein_sequences_n_ids = read_sequences()"
      ],
      "metadata": {
        "id": "zeWa776Z6oCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Removing protein data that is incompatible with my solution.\n",
        "- Removing deprecated entries from dataset. This empty string broke when compared to a label the length of the deprecated sequence.\n",
        "- Removing ambiguous sequences from dataset. My solution only handles the 20 known amino acid codes."
      ],
      "metadata": {
        "id": "rLif_xOQeo_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_pandas_data():\n",
        "\n",
        "  # Removing deprecated entries\n",
        "  clean_pandas_data = pandas_data\n",
        "  non_deprecated_acc = protein_sequences_n_ids.keys()\n",
        "  for acc in pandas_data['acc']:\n",
        "    if acc in non_deprecated_acc:\n",
        "      continue\n",
        "    else:\n",
        "      index_to_drop = clean_pandas_data[clean_pandas_data['acc'] == acc].index.tolist()[0]\n",
        "      clean_pandas_data = clean_pandas_data.drop(index_to_drop)\n",
        "\n",
        "  # Removing ambiguous sequences\n",
        "  for acc in clean_pandas_data['acc']:\n",
        "    seq = protein_sequences_n_ids.get(acc)\n",
        "    # These letter codes are used when an amino acid is ambiguous\n",
        "    if 'X' in seq or 'U' in seq or 'Z' in seq:\n",
        "      index_to_drop = clean_pandas_data[clean_pandas_data['acc'] == acc].index.tolist()[0]\n",
        "      clean_pandas_data = clean_pandas_data.drop(index_to_drop)\n",
        "\n",
        "  return clean_pandas_data.reset_index().drop(columns=['index'])\n",
        "\n",
        "def write_cleaned_pandas_data(pandas_df):\n",
        "  pandas_df.to_json('/content/drive/My Drive/Colab Notebooks/diss_files/idr_pandas_table.json')\n",
        "\n",
        "def read_cleaned_pandas_data():\n",
        "  return pd.read_json('/content/drive/My Drive/Colab Notebooks/diss_files/idr_pandas_table.json')"
      ],
      "metadata": {
        "id": "hBSpgSf24pev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_pandas_data = cleaning_pandas_data()\n",
        "#write_cleaned_pandas_data(cleaned_pandas_data)"
      ],
      "metadata": {
        "id": "LvSnFFs37mo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fully_clean_pandas_data = read_cleaned_pandas_data()"
      ],
      "metadata": {
        "id": "iIY3f1wrZLqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating One-hot map"
      ],
      "metadata": {
        "id": "BiAfa6lNwPyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_empty_channels(seq):\n",
        "  seq_channels = {\n",
        "    'A' : np.zeros(len(seq)),\n",
        "    'C' : np.zeros(len(seq)),\n",
        "    'D' : np.zeros(len(seq)),\n",
        "    'E' : np.zeros(len(seq)),\n",
        "    'F' : np.zeros(len(seq)),\n",
        "    'G' : np.zeros(len(seq)),\n",
        "    'H' : np.zeros(len(seq)),\n",
        "    'I' : np.zeros(len(seq)),\n",
        "    'K' : np.zeros(len(seq)),\n",
        "    'L' : np.zeros(len(seq)),\n",
        "    'M' : np.zeros(len(seq)),\n",
        "    'N' : np.zeros(len(seq)),\n",
        "    'P' : np.zeros(len(seq)),\n",
        "    'Q' : np.zeros(len(seq)),\n",
        "    'R' : np.zeros(len(seq)),\n",
        "    'S' : np.zeros(len(seq)),\n",
        "    'T' : np.zeros(len(seq)),\n",
        "    'V' : np.zeros(len(seq)),\n",
        "    'W' : np.zeros(len(seq)),\n",
        "    'Y' : np.zeros(len(seq))\n",
        "  }\n",
        "  return seq_channels\n",
        "\n",
        "def make_channels(seq):\n",
        "  # Makes 20 empty channels\n",
        "  channeled_seq = make_empty_channels(seq)\n",
        "  # Loop over each amino acid in the sequence - \n",
        "  # for its position add a 1 to the letter identifier channel\n",
        "  for i, char in enumerate(seq):\n",
        "    # Updates array due to arrays being like pointers\n",
        "    channeled_seq.get(char)[i] = 1\n",
        "\n",
        "  return channeled_seq"
      ],
      "metadata": {
        "id": "UpaXPJiKwLpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_onehot_encoding():\n",
        "  onehot_map = {}\n",
        "  for acc in fully_clean_pandas_data['acc']:\n",
        "    channeled_seq = make_channels(protein_sequences_n_ids.get(acc))\n",
        "    onehot_seq = np.array(list(channeled_seq.values()))\n",
        "    onehot_map[acc] = onehot_seq\n",
        "\n",
        "  return onehot_map\n",
        "\n",
        "onehot_map = get_onehot_encoding()"
      ],
      "metadata": {
        "id": "WO8QhAkKwLsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable\n",
        "from json import JSONEncoder\n",
        "class NumpyArrayEncoder(JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return JSONEncoder.default(self, obj)\n",
        "\n",
        "# Save preprocessed one-hot sequences\n",
        "def write_onehot(onehot_map):\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/onehot_data.json', 'w') as outfile:\n",
        "    json.dump(onehot_map, outfile, cls=NumpyArrayEncoder)\n",
        "\n",
        "\n",
        "# Quick access to preprocessed one-hot sequences, instead of recreating the map each time Notebook is opened.\n",
        "def read_onehot():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/onehot_data.json', 'r') as infile:\n",
        "    onehot_map = json.load(infile)\n",
        "    # https://stackoverflow.com/questions/5010536/python-perform-an-operation-on-each-dictionary-value\n",
        "    onehot_map.update((acc, np.array(onehot)) for acc, onehot in onehot_map.items())\n",
        "    return onehot_map\n",
        "\n",
        "# Commented out write onehot, so this file is not accidentally overwritten before processing is ran\n",
        "#write_onehot(onehot_map)\n",
        "onehot_map = read_onehot()"
      ],
      "metadata": {
        "id": "7HhMzkYuwyp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating PSSM map\n",
        "- PSSMs generated by MMSeqs2.\n",
        "- Read in the PSSM and lookup table files.\n",
        "- Write out a dictionary of Accession IDs : PSSMs."
      ],
      "metadata": {
        "id": "8JqsSMeTIMwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pssm_ids_to_accs(id_pssm_map, acc_series):\n",
        "  acc_pssm_map = {}\n",
        "  for k, v in id_pssm_map.items():\n",
        "    acc = acc_series[k]\n",
        "    # This check must be made due to DISPROT containing the latter accession ID, but the PSSM generated with MMSeqs2 produces the former.\n",
        "    # NB: They are the same protein and searching for the latter protein redirects to the former on UniProt.\n",
        "    if acc == 'A0A6L8PPD0':\n",
        "      acc_pssm_map['A0A0F7RL08'] = v\n",
        "    else:\n",
        "      acc_pssm_map[acc] = v\n",
        "\n",
        "  return acc_pssm_map\n",
        "\n",
        "\n",
        "def pssm_parser(fname, lookup):\n",
        "  pssm_file = fname\n",
        "  seq_ids = []\n",
        "  pssms = []\n",
        "  \n",
        "  pssm = []\n",
        "  with open(pssm_file, 'r') as f:\n",
        "    for line in f:\n",
        "      # Start of a new sequence PSSM\n",
        "      if line.startswith(\"Query profile of sequence\"):\n",
        "        # Checks if a PSSM has been read in before this sequence\n",
        "        if len(pssm) > 0:\n",
        "          pssms.append(np.array(pssm).T)\n",
        "\n",
        "        # Get sequence ID and create a new empty data structure to read in this PSSM.\n",
        "        seq_id = line.strip().split()[-1]\n",
        "        seq_ids.append(int(seq_id))\n",
        "        pssm = []\n",
        "        \n",
        "      elif line.startswith(\"Pos\"):\n",
        "        continue\n",
        "      # An amino acids PSSM representation. Parse this into a 20 length vector.\n",
        "      else:\n",
        "        values = line.strip().split()\n",
        "        pssm.append([int(v) for v in values[2:]])\n",
        "    \n",
        "    # Add the final PSSM to the PSSMs list as there are no more new sequences\n",
        "    pssms.append(np.array(pssm).T)\n",
        "\n",
        "  seq_ids = np.array(seq_ids)    \n",
        "  id_pssm_map = dict(zip(seq_ids, pssms))\n",
        "  \n",
        "  # Get lookup table generated by MMSeqs2. This will let us pair the integer sequence IDs to accession IDs.\n",
        "  data = pd.read_csv(lookup, sep='\\t', header=None)\n",
        "  data.columns=['Query Seq', 'ACC', 'IND']\n",
        "  # Get the accession ID series. The index of an accession ID will correlate to the integer sequence ID from the PSSM.\n",
        "  acc_series = data['ACC']\n",
        "\n",
        "  # Getting mapping to acc:PSSM from integer id:PSSM\n",
        "  acc_pssm_map = pssm_ids_to_accs(id_pssm_map, acc_series)\n",
        "  return acc_pssm_map\n",
        "\n",
        "pssms_fname = '/content/drive/My Drive/Colab Notebooks/diss_files/pssms'\n",
        "pssms_lookup = '/content/drive/My Drive/Colab Notebooks/diss_files/ALL.lookup'\n",
        "all_pssms = pssm_parser(pssms_fname, pssms_lookup)"
      ],
      "metadata": {
        "id": "9yIq03wdFS-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save preprocessed pssms\n",
        "def write_pssms(pssm_map):\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/pssm_data.json', 'w') as outfile:\n",
        "    json.dump(pssm_map, outfile, cls=NumpyArrayEncoder)\n",
        "\n",
        "# Quick access to preprocessed pssms, instead of recreating the map each time Notebook is opened.\n",
        "def read_pssms():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/pssm_data.json', 'r') as infile:\n",
        "    pssm_map = json.load(infile)\n",
        "    # https://stackoverflow.com/questions/5010536/python-perform-an-operation-on-each-dictionary-value\n",
        "    pssm_map.update((acc, np.array(pssm)) for acc, pssm in pssm_map.items())\n",
        "    return pssm_map\n",
        "\n",
        "# Commented out write pssms, so this file is not accidentally overwritten before processing is ran\n",
        "#write_pssms(all_pssms)\n",
        "pssm_map = read_pssms()"
      ],
      "metadata": {
        "id": "yfje0A96H6Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting the dataset\n",
        "- Creating a separate train, validation and test set.\n",
        "- Using a seed for reproducible results."
      ],
      "metadata": {
        "id": "lOXtCNUUFuFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "randomly_sampled_pandas_data = fully_clean_pandas_data.sample(frac = 1, random_state=117).reset_index()\n",
        "\n",
        "train_len = round(len(randomly_sampled_pandas_data) * (60/100))\n",
        "train_pandas_data = randomly_sampled_pandas_data[0:train_len]\n",
        "\n",
        "valid_len = round((len(randomly_sampled_pandas_data) * (20/100)))\n",
        "valid_pandas_data = randomly_sampled_pandas_data[train_len:(train_len+valid_len)]\n",
        "# Reset index helps clean up index column after slicing.\n",
        "valid_pandas_data = valid_pandas_data.reset_index(drop=True)\n",
        "\n",
        "test_len = len(randomly_sampled_pandas_data) - (train_len + valid_len)\n",
        "test_pandas_data = randomly_sampled_pandas_data[(train_len+valid_len):]\n",
        "test_pandas_data = test_pandas_data.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "A_eUrM41FtWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handling homologous sequences\n",
        "- Aim is to prevent the leakage of data between protein sequences that occur from a similar evolutionary background."
      ],
      "metadata": {
        "id": "r9Prr9-CQOp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we get the FASTA format of the sequences in each separate dataset, so they can be used in a homology search clustering algorithm."
      ],
      "metadata": {
        "id": "h1iGqtpFHc2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_accs = train_pandas_data['acc'].tolist()\n",
        "validation_accs = valid_pandas_data['acc'].tolist()\n",
        "test_accs = test_pandas_data['acc'].tolist()"
      ],
      "metadata": {
        "id": "-43s34QHFtYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_fasta(acc_list, filename):\n",
        "  FILE_PATH = '/content/drive/My Drive/Colab Notebooks/training_data_files/'+filename\n",
        "  for i, acc in enumerate(acc_list):\n",
        "    url = f'https://www.uniprot.org/uniprotkb/{str(acc)}.fasta'\n",
        "    uniprot_fasta = requests.get(url).text\n",
        "\n",
        "    with open(FILE_PATH, 'a+') as outfile:\n",
        "      outfile.write(uniprot_fasta + '\\n')\n",
        "\n",
        "    if i % 200 == 0:\n",
        "      print(\"Sequence \", i)\n",
        "\n",
        "# Commented out to prevent overwriting\n",
        "#write_fasta(training_accs, 'training_sequences.fasta')\n",
        "#write_fasta(validation_accs, 'validation_sequences.fasta')\n",
        "#write_fasta(test_accs, 'test_sequences.fasta')"
      ],
      "metadata": {
        "id": "-eLYoPfaFtbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MMSeqs2 clustering, plus command line filtering to prepend the dataset name to the accession code, gives us the following TSV that we can continue to preprocess."
      ],
      "metadata": {
        "id": "gZXT-0KrH1OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mmseqs_homo_clusters = pd.read_csv('/content/drive/My Drive/Colab Notebooks/diss_files/clusterRes2_cluster.tsv', sep='\\t', header=None)\n",
        "mmseqs_homo_clusters.columns=['Homo seq', 'Unique seq']\n",
        "mmseqs_homo_clusters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ii0feIsyQH0y",
        "outputId": "1cd132f9-624d-407a-d09a-caa3449adceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Homo seq    Unique seq\n",
              "0     TRAIN_Q9KMA5  TRAIN_Q9KMA5\n",
              "1     TRAIN_Q53654  TRAIN_Q53654\n",
              "2     TRAIN_P53330  TRAIN_P53330\n",
              "3     TRAIN_P12272  TRAIN_P12272\n",
              "4     TRAIN_P12497  TRAIN_P12497\n",
              "...            ...           ...\n",
              "2404   TEST_P12355   TEST_P12355\n",
              "2405   TEST_Q9MAB9   TEST_Q9MAB9\n",
              "2406   TEST_O80358   TEST_O80358\n",
              "2407   TEST_Q9HAU5   TEST_Q9HAU5\n",
              "2408   TEST_P32566   TEST_P32566\n",
              "\n",
              "[2409 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84de2c19-ff5c-4ae4-b478-a519f2c2eb9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Homo seq</th>\n",
              "      <th>Unique seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_Q9KMA5</td>\n",
              "      <td>TRAIN_Q9KMA5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_Q53654</td>\n",
              "      <td>TRAIN_Q53654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_P53330</td>\n",
              "      <td>TRAIN_P53330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_P12272</td>\n",
              "      <td>TRAIN_P12272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_P12497</td>\n",
              "      <td>TRAIN_P12497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2404</th>\n",
              "      <td>TEST_P12355</td>\n",
              "      <td>TEST_P12355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2405</th>\n",
              "      <td>TEST_Q9MAB9</td>\n",
              "      <td>TEST_Q9MAB9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406</th>\n",
              "      <td>TEST_O80358</td>\n",
              "      <td>TEST_O80358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2407</th>\n",
              "      <td>TEST_Q9HAU5</td>\n",
              "      <td>TEST_Q9HAU5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2408</th>\n",
              "      <td>TEST_P32566</td>\n",
              "      <td>TEST_P32566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2409 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84de2c19-ff5c-4ae4-b478-a519f2c2eb9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84de2c19-ff5c-4ae4-b478-a519f2c2eb9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84de2c19-ff5c-4ae4-b478-a519f2c2eb9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_homolgous_sequences():\n",
        "  col1 = mmseqs_homo_clusters['Homo seq']\n",
        "  col2 = mmseqs_homo_clusters['Unique seq']\n",
        "  seeping_sequences = 0\n",
        "  diff_seqs = []\n",
        "  col_1_diff = []\n",
        "  col_2_diff = []\n",
        "\n",
        "  for i, val in enumerate(col1):\n",
        "    # If the homologous sequence is itself, continue as this is not a problem\n",
        "    if val == col2[i]:\n",
        "      continue\n",
        "\n",
        "    # If the homologous sequence is in the same dataset, continue as this is not a problem.\n",
        "    if val[0:5] == \"TRAIN\" and col2[i][0:5] == \"TRAIN\":\n",
        "      continue\n",
        "    elif val[0:3] == \"VAL\" and col2[i][0:3] == \"VAL\":\n",
        "      continue\n",
        "    elif val[0:4] == \"TEST\" and col2[i][0:4] == \"TEST\":\n",
        "      continue\n",
        "    \n",
        "    diff_seqs.append((val, col2[i]))\n",
        "    col_1_diff.append(val)\n",
        "    col_2_diff.append(col2[i])\n",
        "    seeping_sequences += 1\n",
        "\n",
        "  print(\"There are\", seeping_sequences, \"seeping sequences.\")\n",
        "\n",
        "  homo_seqs = {'Homo seq': col_1_diff, 'Unique seq': col_2_diff}\n",
        "  homo_seqs_pd = pd.DataFrame.from_dict(homo_seqs)\n",
        "  return homo_seqs_pd"
      ],
      "metadata": {
        "id": "zjpVPqq2P96U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "homo_seqs_pd = identify_homolgous_sequences()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km6GW1Q1OwTz",
        "outputId": "511879cd-26b6-4ded-a393-5979b1f379e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 286 seeping sequences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function creates a map so we can move all homologous sequences into a dataset with sequences they are homologous to.\n",
        "# Prevents data leakage between datasets.\n",
        "def moving_dataset(pandas_data):\n",
        "  moved_dataset_map = {}\n",
        "  for i, val in enumerate(pandas_data['Homo seq']):\n",
        "    if val[0:5] == \"TRAIN\":\n",
        "      over_writing_seq = pandas_data['Unique seq'][i]\n",
        "      if over_writing_seq[0:3] == \"VAL\":\n",
        "        moved_dataset_map[over_writing_seq] = \"TRAIN\" + over_writing_seq[3:]\n",
        "      else:\n",
        "        moved_dataset_map[over_writing_seq] = \"TRAIN\" + over_writing_seq[4:]\n",
        "\n",
        "    elif val[0:3] == \"VAL\":\n",
        "      over_writing_seq = pandas_data['Unique seq'][i]\n",
        "      if over_writing_seq[0:5] == \"TRAIN\":\n",
        "        moved_dataset_map[over_writing_seq] = \"VAL\" + over_writing_seq[5:]\n",
        "      else:\n",
        "        moved_dataset_map[over_writing_seq] = \"VAL\" + over_writing_seq[4:]\n",
        "\n",
        "    elif val[0:4] == \"TEST\":\n",
        "      over_writing_seq = pandas_data['Unique seq'][i]\n",
        "      if over_writing_seq[0:5] == \"TRAIN\":\n",
        "        moved_dataset_map[over_writing_seq] = \"TEST\" + over_writing_seq[5:]\n",
        "      else:\n",
        "        moved_dataset_map[over_writing_seq] = \"TEST\" + over_writing_seq[3:]\n",
        "\n",
        "  return moved_dataset_map\n",
        "\n",
        "moved_dataset_map = moving_dataset(homo_seqs_pd)"
      ],
      "metadata": {
        "id": "KkNBajuPThfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleans acc labels and moves sequences between datasets.\n",
        "def organise_sequences():\n",
        "  train_accs = []\n",
        "  validation_accs = []\n",
        "  test_accs = []\n",
        "\n",
        "  transfer_seqs = moved_dataset_map.keys()\n",
        "  for val in mmseqs_homo_clusters['Unique seq']:\n",
        "    # Check if sequence needs to be moved dataset\n",
        "    if val in transfer_seqs:\n",
        "      acc = moved_dataset_map.get(val)\n",
        "    else:\n",
        "      acc = val\n",
        "\n",
        "    # Remove randomly split dataset identification\n",
        "    if acc[0:5] == \"TRAIN\":\n",
        "      train_accs.append(acc[6:])\n",
        "    elif acc[0:3] == \"VAL\":\n",
        "      if acc[4:] == 'A0A6L8PPD0':\n",
        "        new_acc = 'A0A0F7RL08'\n",
        "        validation_accs.append(new_acc)\n",
        "        continue\n",
        "      validation_accs.append(acc[4:])\n",
        "    elif acc[0:4] == \"TEST\":\n",
        "      test_accs.append(acc[5:])\n",
        "\n",
        "  return train_accs, validation_accs, test_accs\n",
        "\n",
        "train_accs, validation_accs, test_accs = organise_sequences()\n",
        "dataset_split = {'Train': train_accs, 'Validation': validation_accs, 'Test': test_accs}"
      ],
      "metadata": {
        "id": "4H7CjMbGV0Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the split of our datasets is still appropriate\n",
        "print(\"Train new percentage \", round(len(train_accs) / 2409 * 100))\n",
        "print(\"Valid new percentage \", round(len(validation_accs) / 2409 * 100))\n",
        "print(\"Test new percentage \", round(len(test_accs) / 2409 * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9mkL_maV0OI",
        "outputId": "64c4a98b-01b7-4407-be63-b9bbfed14d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train new percentage  62\n",
            "Valid new percentage  19\n",
            "Test new percentage  19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save preprocessing of homologous sequence solution\n",
        "def write_homo_solution(split):\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/homo_solution.json', 'w') as outfile:\n",
        "    json.dump(split, outfile)\n",
        "\n",
        "# Quick access to preprocessed dataset split, instead of doing this each time Notebook is opened.\n",
        "def read_homo_solution():\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/diss_files/homo_solution.json', 'r') as infile:\n",
        "    return json.load(infile)\n",
        "\n",
        "\n",
        "# Commented out write homo solution, so this file is not accidentally overwritten before processing is ran\n",
        "#write_homo_solution(dataset_split)\n",
        "non_leaking_dataset_split = read_homo_solution()"
      ],
      "metadata": {
        "id": "PUiZLSiiV0Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uV_AAEeLbEvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}